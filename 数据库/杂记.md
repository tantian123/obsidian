ARIES 经典的 Recovery 算法 核心思想是 WAL with STEAL/NO-FORCE ->引出redo undo/physical logging 和 logical logging-

并发控制（Concurrency Control）和故障恢复（Crash Recovery） ->lsn Checkpoint ->回滚 ->事务的几个概念 ->buffer pool double write

->InnoDB引擎有几个重点特性
插入缓冲（Insert Buffer） 两次写（Double Write） 自适应哈希索引（Adaptive Hash Index） 异步IO（Async IO） 刷新邻接页（Flush Neighbor Page）

redo log 的作用。 既可以仅采用 undo 或 redo 日志，也可以结合两者，都能实现事务的一致性 但是结合 undo/redo 日志要求数据库系统在运行时仅需要保证一条原则： WAL 策略：如果事务 T 更新一个记录 X，产生的日志 <Trx-id, X, before-image, after-image> 必须先于对应的脏记录落盘 而脏记录可以在事务执行时随时落盘（steal），甚至事务提交后依然允许部分脏页在 buffer pool 的 flush list 中慢慢的落盘（no-force）

Undo Log用来记录每次修改之前的历史值，配合Redo Log用于故障恢复。 数据库实现中通常会在正常事务进行中，就不断的连续写入Undo Log，来记录本次修改之前的历史值。当Crash真正发生时，可以在Recovery过程中通过回放Undo Log将未提交事务的修改抹掉。InnoDB采用的就是这种方式。 ，在正常运行过程中，死锁处理或用户请求的事务回滚也可以利用这部分数据来完成事务回滚。

在记录操作信息时，通常有两种方案：physical logging 和 logical logging。前者指的是记录物理数据的变化；后者指的是记录逻辑操作内容，如 UPDATE、DELETE 和 INSERT 语句等 Undo Log采用了基于事务的Logical Logging的方式 redo log是physical logging

undo log 是Logical 里记录的就是每个修改的 row 的 before image

为什么组合使用 undo 日志存储的是记录的旧值（before image），redo 日志存储的是记录的新值（after image）。比如事务 T 更新记录 A 由 7 -> 8:undo 日志：<T, A, 7>，事务 T 修改了 A， 修改前 A 是 7redo 日志： <T, A, 8>，事务 T 修改了 A， 修改后 A 是 8undo / redo 日志：<T, A, 7, 8>，事务 T 修改了 A， 修改前 A 是 7，修改后 A 是 8

仅使用 undo 日志的 steal / force 策略 因为是force 所以所有的 redo 日志都已落盘 不用考虑 仅使用 redo 日志的 no-steal / no-force 策略 因是no-steal 这样一个事务写磁盘的顺序是：redo 日志，commit 日志和脏记录 undo / redo 日志结合

回滚的过程:??? 事务回滚过程中会不断地调用trx_roll_pop_top_rec_of_trx_low这个函数。这个函数的作用是从undo日志（undo log）中取出最顶层（即最近添加的）undo记录（undo log record） 取出undo记录后，系统会根据这些记录的信息，逆向执行相应的操作来撤销对索引记录（index record）的更改。例如，如果一个事务增加了一条记录，那么在回滚过程中就会删除这条记录；如果事务删除了一条记录，回滚时则会重新插入这条记录

事务的几个概念: 逻辑时间 视图（read view） 描述的是在该事务开始时刻数据库系统中所有事务的总体状态。 在每个事务 T 开始时，都会将那一时刻 rx:sys::rw_trx_ids 的快照拷贝一份作为该事务的”局部变量“（trx_t::read_view::m_ids），trx_t::read_view 则记录了该事务开始时刻，数据库系统中所有事务的总体状态。我们把 trx_t::read_view::m_ids 中最小值作为 read_view::m_up_limit_id（高水位），拷贝 rx:sys::rw_trx_list 快照时的 trx_sys::max_trx_id（系统时钟）作为 read_view::m_low_limit_id（低水位）

class ReadView { trx_id_t m_low_limit_id; //m_ids中的最小值 trx_id_t m_up_limit_id;//m_ids中的最大值 ids_t m_ids; //那一时刻的存活事务ids }

MVCC意图解决2PL中读写的互相阻塞

b tree why? ->并发控制使用两种 latch：index latch / page latch ->基础并发控制机制 SL XL SXL ->数据页的分裂

记录的存在形式分为物理记录（record）和逻辑记录（tuple），物理记录即是记录在文件中（磁盘）的存储形式

逻辑记录即是在内存中的表示（data structure）

innodb索引树： 每一个 record 由 key + value 组成， 非叶子节点的key保存子节点中最小的key，value指向子节点 叶子节点的key指向该数据行的唯一属性组成的若干列，value指向其余列

同一page内的record形成record list 同一高度的page 连接成 双向链表，称作 page list

并发控制使用两种 latch：index latch / page latch

基础并发控制机制（MySQL5.6）: MySQL5.6以及之前的版本采用了一种较为基础的并发机制：它采用了两种粒度的锁：（1）index粒度的S/X锁；（2）page粒度的S/X锁（本文等同于树节点粒度） S :share锁 X：Exclusive 锁

加锁过程： /* Algorithm1. 读操作 */

SL(index)
Travel down to the leaf node
SL(leaf)
SU(index)
Read the leaf node
SU(leaf)
读操作首先对整个B+树加S锁（step1），其次访问树结构直到对应的叶节点（step2），接着对叶节点的page加S锁（step3），再释放index的S锁（step4），然后访问叶节点的内容（step5），最后释放叶节点的S锁（step6）

对于死锁问题，MySQL5.6采用的是“从上到下，从左到右”的加锁顺序，不会出现两个线程加锁顺序成环的现象，所以不会出现死锁的情况

从MySQL5.6版本升级到5.7版本的过程中，B+树的并发机制发生了比较大的变化，主要包括以下几点：（1）引入了SX锁；（2）写操作尽可能只锁住修改分支，减少加锁的范围

数据页的分裂: 在频繁插入新记录的情况下，如果主键列上的值不是递增的，可能会导致页分裂。为了减少页分裂，建议使用自增主键

Double Write 解决的问题（因为数据库的最小IO单位是page或者block，MySQL 默认是16kb，而本操作系统的最小IO单位一般为4kb，所以在进行刷盘操作时，需要四次IO才能将16KB的数据页刷入磁盘 但当执行完第二次IO时，数据库发生意外宕机，导致此时才刷了2个文件系统里的页，这种情况被称为写失效partial write 此时重启后，磁盘上就是不完整的数据页，就算使用redo log redolog 没有记录该页的全部数据，所以不能恢复）

因为数据库使用的页（page，默认16KB）大小和操作系统对磁盘的操作页（page，默认4KB）不一样，当提交了一个页需要刷新到磁盘，会有多次IO， 此时刷了前面的8k时异常发生宕机。在系统恢复正常后，如果没有double write机制，此时数据库磁盘内的数据页已损坏，无法使用redo log进行恢复。

如果有double write buffer，会检查double writer的数据的完整性，如果不完整直接丢弃double write buffer内容，重新执行那条redo log，如果double write buffer的数据是完整的，用double writer buffer的数据更新该数据页，跳过该redo log

在数据库进行脏页刷新时，如果此时宕机，有可能会导致磁盘数据页损坏，丢失我们重要的数据。此时就算重做日志也是无法进行恢复的，因为重做日志记录的是对页的物理修改

其实就是在重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是double write 但它与传统的buffer又不同，传统buffer是纯内存的,而它分为内存和磁盘的两层架构

过程：buffer页数据先copy到DWB的内存里； DWB的内存数据刷到DWB的磁盘上； DWB的内存再刷到数据磁盘上；

Double Write 的问题 Double write buffer 它是在物理文件上的一个buffer, 其实也就是file，所以它会导致系统有更多的fsync操作，而因为硬盘的fsync性能问题，所以也会影响到数据库的整体性能。

PG在很早的版本就引入了full page write机制，来避免这种partial write问题。 核心是将整个page 的内容到wal日志 会导致wal日志的疯狂增长，同时对性能也会有一定影响 Oracle 中不是没有partial write的问题，而是Oracle 本身具有很多数据块的完整校验机制，写失败就直接回滚掉了

buffer pool 本质上是一个 cache，提供读 / 写两种基本操作

https://www.bookstack.cn/read/aliyun-rds-core/6e1235deb1b15396.md 极客时间课程 http://mysql.taobao.org/monthly/

传统磁盘数据库使用两层结构——使用快速易失性的内存作缓存，慢速持久性的设备用作主要存储 因此这些系统使用buffer pool以及复杂的并发控制方案来掩盖磁盘延迟 但新兴的非易失性内存（NVM）技术需要我们重新审视这种二分法。这种内存设备比DRAM慢，但是所有写入即使在断电后都是持久性的

Redo和Undo是用于实现事务持久性和回滚功能 针对大内存的 In-Memory 数据库，所有数据都放在内存中，只需要 Redo 不需要 Undo； 也有正在发展的 NVM 数据库，事务提交时无脑刷盘，只需要 Undo 不需要 Redo（WBL 协议）

在In-Memory数据库中，因为数据的易失性，主要关注的是如何通过Redo日志来确保数据的持久性；而在NVM数据库中，由于数据本身具有持久性，重点转向了如何高效地管理事务的回滚，因此更多依赖于Undo日志

那为什么经典的数据库需要redo undo呢： STEAL NO FORCE

https://zhuanlan.zhihu.com/p/109417488 redolog Physiological Logging 所谓Physiological Logging，就是以Page为单位，但在Page内以逻辑的方式记录

undolog 并发控制（Concurrency Control）和故障恢复（Crash Recovery） Undo for MVCC和 Undo for Rollback

Undo Log用来记录每次修改之前的历史值，配合Redo Log用于故障恢复。 数据库实现中通常会在正常事务进行中，就不断的连续写入Undo Log，来记录本次修改之前的历史值。当Crash真正发生时，可以在Recovery过程中通过回放Undo Log将未提交事务的修改抹掉。InnoDB采用的就是这种方式。 ，在正常运行过程中，死锁处理或用户请求的事务回滚也可以利用这部分数据来完成事务回滚。

在记录操作信息时，通常有两种方案：physical logging 和 logical logging。前者指的是记录物理数据的变化；后者指的是记录逻辑操作内容，如 UPDATE、DELETE 和 INSERT 语句等 Undo Log采用了基于事务的Logical Logging的方式

ARIES 经典的 Recovery 算法 保证事务的原子性和持久性

核心思想是 WAL with STEAL/NO-FORCE，Repeating history during redo 以及 Logging changes during undo，支持 Page-Oriented Redo，Logical Undo ，Fuzzy Checkpoint，Partial Rollback，Nested Top Actions

Page会由Buffer Pool管理 如果对某个 Page 的更新已经反映到内存中的副本上，尚未反映到磁盘上的副本上，我们就说这个 Page 是 Dirty Page

Dirty Page的刷盘时机 STEAL：允许将未提交事务的改动刷盘。 NO-STEAL：与 STEAL 相反。 FORCE：必须在事务提交时把该事务的所有改动刷盘。 NO-FORCE：与 FORCE 相反。

Buffer Pool 可以在 STEAL 和 NO-STEAL 中二选一，然后在 FORCE 和 NO-FORCE 中二选一，组成自己的策略。 STEAL能 避免大量堆积 NO FORCE减少了刷盘次数

其实就是在RUNTIME和RECOVERY 之间tradeoff，大多数数据库都更看重 Runtime 性能

WAL 协议要求更新任意 Page 都要记录 Log 必须保证所有 Page 刷盘之前与它有关的所有 Log 已经刷盘。 必须保证事务提交前该事务的所有 Log 已经刷盘

Checkpoint 在 Log 中打了一个标记，我们认为这个标记之前的所有 Log 都不会被再用到，Recovery 期间可以直接跳过 加快recovery的速度

通常有 Consistent Checkpoint 和 Fuzzy Checkpoint 两个方案 Consistent Checkpoint 1.从上一个事务提交后开始，禁止新事务 2.遍历BufferPool 将所有Dirty Page刷盘 3.记录一条Checkpoint log 4.允许事务

Recovery 直接从 Checkpoint Log 开始，之前的 Log 一律跳过。

为了做 Checkpoint 而使数据库停服不可接受。ARIES 提出了一种 Fuzzy Checkpoint 的方案

2.并发控制

https://zhuanlan.zhihu.com/p/45339550 https://zhuanlan.zhihu.com/p/294657612

对常见的并发控制机制进行分类： 根据乐观程度的不同 乐观的并发控制 OCC TS 悲观的并发控制 2PL

基于Lock：最悲观的实现，需要在操作开始前，甚至是事务开始前，对要访问的数据库对象加锁，对冲突操作Delay； 数据库中常用的加锁方式称为两阶段锁（2PL），Growing阶段可以申请加锁，Shrinking阶段只能释放 (2PL 的 Lock 和“读写锁” “自旋锁”这些同步操作不是一回事，后者在 DB 层被称为 Latch) 增长阶段（Growing Phase）： 在这个阶段，事务可以申请新的锁。 事务可以获取共享锁或排他锁，但不能释放任何锁。 收缩阶段（Shrinking Phase）： 在这个阶段，事务只能释放锁，不能申请新的锁。 收缩阶段从事务第一次释放锁开始，直到事务提交或回滚

Growing：仅获取锁或者拒绝获取锁的请求 Shrinking：只允许释放锁

基于Timestamp：乐观的实现，每个事务在开始时获得全局递增的时间戳，期望按照开始时的时间戳依次执行，在操作数据库对象时检查冲突并选择Delay或者Abort；

基于Validataion（OCC）：更乐观的实现，仅在Commit前进行Validate，对冲突的事务Abort

对应上述每种乐观程度，都可以有多版本的实现方式（多版本的目的是为了避免写事务和读事务的互相等待） 多版本的优势在于，可以让读写事务与只读事务互不干扰，因而获得更好的并行度 多版本，就是在每次需要对数据库对象修改时，生成新的数据版本，每个对象的多个版本共存。读请求可以直接访问对应版本的数据，从而避免读写事务和只读事务的相互阻塞。当然多版本也会带来对不同版本的维护成本，如需要垃圾回收机制来释放不被任何事物可见的版本

为了实现多版本的并发控制，需要给每个事务在开始时分配一个唯一标识TID，并对数据库对象增加以下信息：

txd-id，创建该版本的事务TID begin-ts及end-ts分别记录该版本创建和过期时的事务TID pointer: 指向该对象其他版本的链表 其基本的实现思路是，每次对数据库对象的写操作都生成一个新的版本，用自己的TID标记新版本begin-ts及上一个版本的end-ts，并将自己加入链表。读操作对比自己的TID与数据版本的begin-ts，end-ts，找到其可见最新的版本进行访问

MV2PL MVTO MVOCC

无论是乐观悲观的选择，多版本的实现，读写锁，两阶段锁等各种并发控制的机制，归根接地都是在确定的隔离级别上尽可能的提高系统吞吐，可以说隔离级别选择决定上限，而并发控制实现决定下限

1.1基于lock 基于Lock实现的Scheduler需要在事务访问数据前加上必要的锁保护，为了提高并发，会根据实际访问情况分配不同模式的锁，常见的有读写锁，更新锁等

MVCC的两种实现方式 活跃事务表和时间戳 活跃事务表：PG 的 Snapshot，MySQL 的 ReadView MySQL 同样是为每个事务分配一个 txn-id。但与 PG 的 append-only storage 不同，MySQL 的数据存储是一种 delta storage。所谓 delta storage，指的就是对 main table 中数据的更新，会把被更新的字段（这就是 delta 部分）备份到专门的存储（undo storage）里面，然后把老版本原地更新为新版本，同时维护新版本指向旧版本的指针。这个做法相比 PG 来说，对读性能更加友好一些，因为老版本不会造成 main table 的数据膨胀，增加读放大。

对于 abort 的事务，MySQL 的处理与 PG 不同，MySQL 是更纯正的 ARIES recovery 算法的继承者（事务不仅记录 redo 日志，还会记录 undo 日志），事务回滚时，会直接把 abort 的版本 undo 一下，直接清理掉。因此数据存储中可以认为不存在 aborted 的版本。这个做法相比 Postgres 来说，在事务状态存储方面简单了很多，aborted 事务的状态不需要较长期地维护

现代数据库广泛采用 MV2PL 协议来实现 Concurrency Control

B-tree 并发控制

为了追求更高的事务并发度，B+Tree数据库区分了用户可见的逻辑内容和内部维护的物理结构，在并发控制上支持了Lock和Latch的分层，同时也在故障恢复上区分了User Transaction和System Transaction；System Transaction由数据库内部发起，通常修改较少的一两个Page，提交时间可控，因此通常采用Redo + No Steal的策略，来避免写Undo Log；在User Transaction需要回滚时，由于之前的System Transaction可能已经提交，其改变的物理结构，如新分裂的Page已经被其他事物使用。因此需要在User Transaction层的采取逆操作的方式进行回滚，逆操作同样需要发起System Transaction。User Transaction的回滚不能回退物理结构的变化，比如Page分裂，这一点正好可以被System Transaction保证。执行Crash Recovery时，需要先做System Transaction的故障恢复，由于其Redo + No Steal的实现，这里只需要重放其Redo Log。之后做User Transaction的Undo重放。由于分层实现，Redo Log是由System Transction产生的，天然需要Page Oriented，而Page内日志为了减少日志量和存储开销，通常采用Logical的实现，因此Redo Log通常采用被称为Physiological Logging的方式。对应的User Transaction层产生的Undo Log采用Logical Logging的方式。 https://zhuanlan.zhihu.com/p/613532094

在数据库中，有两种锁，一种叫 Lock，用来锁一些逻辑的对象（e.g., 表锁，行锁）以支持事务并发控制；另一种叫 latch，用来锁一些物理的数据结构（如 B-tree 并发读写加的锁）以实现数据结构的正确读写（search/insert/delete）。本文要讲的 B-tree 的并发控制的演进，指的就是这个 B-tree 上的 latch 的一个演进（优化）的历程

B-tree 并发控制要解决什么问题呢？ 1.正在读取/写入的结点被并发线程篡改，读到不一致的结点状态（读写并发和写写并发) 2.子结点指针失效,并发写线程把子结点写满了，子结点发生了 split，一部分数据挪到了子结点右边的新结点上去了

最简单粗暴的方案就是在读写 B-tree 时，直接加一把整个 B-tree 级别的大锁。search 操作加读锁，insert/delete 加写锁

有一个优化的方案：latch crabbing。latch crabbing 方案锁的粒度降低到 B-tree 结点级别，对结点加读写锁。 具体的规则是： Search 操作下降过程中自上而下对结点加读锁。获得子结点的锁后，可立即释放父结点的锁。 Insert/delete 操作下降过程中自上而下对结点加写锁。获得子结点的锁后，判断子结点是否 safe，如果是，可立即释放所有祖先结点的写锁

结合Latch和Lock方案，已经可以很好的支持对单条Record的增删改查。但很多数据库访问并不是针对某一条记录的，而是基于条件的。比如查询满足某个条件的所有Record，这个时候就会出现《数据库事务隔离发展历史》[5]中提到的幻读的问题，也就是在事务的生命周期中，由于新的满足条件的Record被其他事务插入或删除，导致该事务前后两次条件查询的结果不同。

最直接的想法是对所有可能的，还不存在的Key也加锁 传统的解决幻读的方案是谓词锁(Predicate Lock)，也就是直接对查询条件加锁，每次插入删除需要判断是否与现有的判断条件冲突，但通用数据库中，条件千变万化，判断条件冲突这件事情开销极大。也正是因此，谓词锁并没有成为主流。在B+Tree上，由于其Key有序的特点，通常会采用Key Range Locking，也就是对Key加锁，来保护其旁边的区间Range

高频率顺序插入的场景，这个Next Key Lock就会成为明显的瓶颈。Instant Locking的方案很好的解决了这个问题。顾名思义，Instant Locking只在瞬间持有这把Next Key Locking，其加锁是为了判断有没有这个Range冲突的读操作，但获得锁后并不持有，而是直接放锁。乍一看，这样违背了2PL的限制，使得其他事务可能在这个过程获得这把锁。通过巧妙的利用Btree操作的特性，以及Latch及Lock的配合，可以相对完美的解决这个问题

==============

数据库索引 in-memory索引用的skiplist 为什么 磁盘数据库使用btree

Tree vs Hash？ key有序存储，功能上可以支持范围遍历。 索引不要求all in memory（而hash从磁盘load很慢 只能放在内存中 占用太多内存），对硬件要求更小

可以对比Leveldb和bitcask Bitcask 是一个哈希，只能存无序数据；Leveldb 可以储有序数据，有序数据总是相邻地存储，应用程序可以利用存储的局部性 Bitcask 将索引整个放在内存里，键过多时，会占据过多内存，Leveldb 中每个 Level 一个 Manifest 用于索引每个 SSTable 的范围，占据的内存较小

Hash有个问题就是在内存里能高效存取，但是在磁盘上不行 所以只能用于内存数据库 range scan

https://www.bookstack.cn/read/aliyun-rds-core/6c29a18a52fa318c.md B+树 采用多叉树结构，降低了索引结构的深度，避免传统二叉树结构中绝大部分的随机访问操作，从而有效减少了磁盘磁头的寻道次数，降低了外存访问延迟对性能的影响。它保证树节点中键值对的有序性，从而控制search/insert/delete/update操作的时间复杂度在O(log(n))的范围内

lsm讲讲写流程和读流程 数据会首先写到WAL log中 写到内存的memtable中（是个skiplist） 大小达到阈值后变为immutable 后续交给新的memtable immutable刷到磁盘的sstable，并且释放WAL Log 插入sstable后 如果当前层大小超过阈值 就将sstable与下层合并

读取： 如果Key在memtable中，那么直接读取返回；否则自上而下地读取SST

读sstable的流程如下：

FindFiles。从SST文件中查找，如果在 L0，那么每个文件都得读，因为 L0 不保证Key不重叠； 如果在更深的层，那么Key保证不重叠，每层只需要读一个 SST 文件即可。L1 开始，每层可以在内存中维护一个 SST的有序区间索引，在索引上二分查找即可 LoadIB + FB。 IB 和 FB 分别是 index block 和 filter block 的缩写。index block是SST内部划分出的block的索引；filter block 则是一个布隆过滤器（Bloom Filter），可以快速排除 Key 不在的情况，因此首先加载这两个结构 SearchIB。二分查找 index block，找到对应的block SearchFB。用布隆过滤器过滤，如果没有，则返回 LoadDB。则把这个block加载到内存 SearchDB。在这个block中继续二分查找 ReadValue。找到 Key后读数据

对每个sstable 使用（bloom filter）,以加速对数据在该sstable 的存在性进行判定

LSM-tree的设计是基于HDD的，而在SSD日渐普及的今天，HDD的“蜜糖”就成了SSD的“砒霜”。HDD中，顺序I/O比随机I/O快100x，但是在SSD中，两种I/O的差别已经没那么大。这时候LSM-tree中大量的顺序I/O反而可能会造成带宽浪费。

传统硬盘（HDD，Hard Disk Drive的缩写） 固态硬盘（Solid State Drive） 针对这些差异，Wisconsin的研究者们在LevelDB的基础上，提出WiscKey

不使用原地更新操作来实现更好的性能 异地更新（out-of-place）作为更新策略 所有的更新操作会先写到differential file里，并且周期性地被合并到main file

顺序磁盘访问比随机访问主内存更快 快三个数量级 它们有一个明显的缺点。从日志中读取任意数据将比写入数据耗时得多，涉及逆向时间扫描，直到找到所需的键

有四种方法可以帮助我们：二分查找、哈希、B+ 或外部文件。 所有这些方法都能显著提高读取性能（从 O(n) 提高到 O(log(n))）。遗憾的是，这些结构增加了秩序，这阻碍了写入性能，所以我们高速的日志文件就这样丢失了。你不能两全其美。 一种常见的解决方案是使用第 (4) 种方法——日志的索引，但将索引保留在内存中。例如，可以使用哈希表将键映射到日志文件（日志）中最新值的位置（偏移量）。这种方法实际上效果很好，因为它将随机 I/O 隔离到相对较小的部分 查找值只需要一次 I/O。 。最常见的方法是在内存中持有页面索引。这提供了一个查找功能，可以让你接近目标键。然后你可以从那里开始扫描

定期，系统会执行一次压缩。压缩选择多个文件并将它们合并在一起，移除任何重复的更新或删除操作，由于文件是排序的，合并文件的过程相当高效。

即使进行了压缩，读取操作可能仍需访问多个文件。大多数实现通过使用布隆过滤器来避免这种情况。布隆过滤器是一种内存高效的确定文件是否包含某个键的方法。

主要由以下组件组成 log: write-ahead logging是数据库的一种常见手段（WAL (Write Ahead Log) 预写日志），数据按照 ->log->mem 的顺序更新，由于数据已经持久化到磁盘，因此即使进程异常也能够保证数据的完整性，同时这里是追加写，因此写性能极高 日志（‌WAL - Write-Ahead Log）‌：‌保证数据的持久性，‌在数据写入MemTable的同时写入日志，‌以便系统崩溃后恢复数据。

memtable内存数据结构: 最近写入的 key-value 数据，内存存储，读取数据首先从这里查找。（ memtable，其底层则用 skiplist 来实现，在存储系统的内存表中使用跳表，整个跳表始终保持有序状态）

immutable memtable: 为了限制内存大小，当 memtable 达到一定大小后，会转换为immutable memtable。后台线程会把immutable memtable 持久化到硬盘，持久化的文件称为 level-0 sstable

sstable: 由上层(or上上层)的 sstable 合并成新的sstable，并写入到下一层

leveldb 无论哪一层文件，都是 sstable 的格式，即 Sorted String Table。 被设计用于存储大量的 {key:value} 数据，当我们在 leveldb 查找某个 key 时，可能需要逐层查找多个 sstable 文件。 sstable 在文件格式设计上，主要考虑： 查找速度，通过建索引解决 文件大小，通过压缩解决

Bloom Filter：‌减少非必要的磁盘读取，‌快速判断键值是否存在于某个SSTable中。‌

使用一个专门的后台线程定期地把不可变的 MemTable 从内存持久化到磁盘。一旦刷盘（flush）完成，不可变的 MemTable 和相应的 WAL 就会被丢弃

数据库的并发控制是由事务和锁共同完成的 并发控制机制： 基于lock的和基于时间戳的 是否是多版本的（是读写互斥的 为了更好的并行度） lock timestamp Validation（OCC） https://zhuanlan.zhihu.com/p/294657612 https://dev.mysql.com/doc/refman/8.0/en/innodb-locking.html#innodb-shared-exclusive-locks https://zhuanlan.zhihu.com/p/462576086

btree latch 在innodb5.6中的实现 https://zhuanlan.zhihu.com/p/151397269

看catKang的加锁的历史演进 ARIES主论文 ARIES/KVL ARIES/IM 索引方面 https://zhuanlan.zhihu.com/p/511202971

数据库月报 mysql.taobao.org/monthly/2020/06/02/ http://mysql.taobao.org/monthly/2020/05/02/ http://mysql.taobao.org/monthly/2020/11/02/ http://mysql.taobao.org/monthl

MVCC 给每个事务在开始时分配一个唯一标识TID 并对数据库对象增加以下信息： txd-id，创建该版本的事务TID begin-ts及end-ts分别记录该版本创建和过期时的事务TID pointer: 指向该对象其他版本的链表

对数据库对象的写操作都生成一个新的版本 用自己的TID标记新版本begin-ts及上一个版本的end-ts，并将自己加入链表 对数据库对象的读操作对比自己的TID与数据版本的begin-ts，end-ts，找到其可见最新的版本进行访问

悲观的 首先 2PL 的 Lock 和“读写锁” “自旋锁”这些同步操作不是一回事，后者在 DB 层被称为 Latch 保证可串行化的2PL： 2PL协议要求事务必须分两个阶段加锁和解锁 1.事务可以获取锁 但不能释放锁 2.事务只可以释放锁

2PL这个时期的加锁策略认为树节点是最小的加锁单位。由于B+Tree的从根向下的搜索模式，事务需要持有从根节点到叶子节点路径上所有的锁。而两阶段锁(2PL)又要求所有这些锁都持有到事务Commit。更糟糕的是，任何插入和删除操作都有可能导致树节点的分裂或合并（Structure Modification Operations, SMO），因此，对根结点需要加写锁WL

下一阶段 对Record加Lock而不是Page 用户A和用户B分别转账给用户C一笔钱 最高层L2从用户角度看，A和B的账户上的金额减少，C的账户金额增加；中间层L1在记录角度，代表A和B账户金额的Record x、Record y做了查询以及更新操作，而代表C账户金额的Record z做了更新操作；最下层L0站在Page的角度，Record x以及y都在Page p上，而Record z在Page q上，因此Page p以及Page q都被两个事务读写。按照上面讲到的对Page加Lock的做法，T2必须等T1执行完成并释放p，q两个Page上的锁。这种接近串行的并发度当然不是我们想要的

因此需要分层事务 如果能在L1层，也就是对Record而不是Page加锁，就可以避免T1和T2在Page p Lock上的等待沿着这个思路，ARIES/KVL出现了。 ARIES/KVL首先明确的区分了B+Tree的物理内容和逻辑内容，逻辑内容就是存储在B+Tree上的那些数据记录，而B+Tree自己本身的结构属于物理内容，物理内容其实事务是不关心的，那么节点分裂、合并这些操作其实只是改变了B+Tree的物理内容而不是逻辑内容。因此，ARIES/KVL就将这些从Lock的保护中抽离出来，也就是Lock在Record上加锁，对物理结构则通过Latch来保护其在多线程下的安全。这里最本质的区别是Latch不需要在整个事务生命周期持有，而是只在临界区代码的前后，这其实也可以看作上面分层事务的一种实现 Latch保护物理结构 Lock保护逻辑结构 有了这种清晰的区分，事务的并发控制就变得清晰很多，不再需考虑树本身的结构变化 前面这套结合Latch和Lock方案，已经可以很好的支持对单条Record的增删改查。但很多数据库访问并不是针对某一条记录的，而是基于条件的。比如查询满足某个条件的所有Record，这个时候就会出现《数据库事务隔离发展历史》[5]中提到的幻读的问题，也就是在事务的生命周期中，由于新的满足条件的Record被其他事务插入或删除，导致该事务前后两次条件查询的结果不同。这其实是要求，条件查询的事务和插入/删除满足这个条件Record的事务之间，有相互通信或冲突发现的机制，最直接的想法是对所有可能的，还不存在的Key也加锁，在大多数情况下，由于Key范围的无限，这都是不可接受的。传统的解决幻读的方案是谓词锁(Predicate Lock)，也就是直接对查询条件加锁，每次插入删除需要判断是否与现有的判断条件冲突，但通用数据库中，条件千变万化，判断条件冲突这件事情开销极大。也正是因此，谓词锁并没有成为主流。在B+Tree上，由于其Key有序的特点，通常会采用Key Range Locking，也就是对Key加锁，来保护其旁边的区间Range，有很多中选择

关系型数据库有不同的层次：

Database table Page Tuple/Row Column

为什么有意向锁？

层次低的话，分配更多低层次锁，允许更高的并行度，但是 LockTable 会面临更大的时空开销（主要是内存/CPU） 分配高层次锁，可能的并行度会降低，但是 LockTable 面临的时空开销减小。

同时，实现者在 LockTable 维护 Lock 的时候，会发现，协调不同层次的锁是困难的，而且从 Root 开始锁定开销过大，因此有了 intention locks IS: Intention-Shared，希望更细粒度的获得 shared lock IX: Intention-Exclusive: 希望获得更细粒度的 exclusive lock SIX: S + IX

根据乐观程度多版本的机制也分为三类： MV2PL MVTO MVOCC

lock 和 latch

InnoDB 存储引擎中的锁 InnoDB 实现了两种标准的行级锁: 共享锁（S Lock），允许事务读一行数据。 排他锁（X Lock），允许事务删除或更新一行数据

InnoDB 有 3 种行锁的算法，分别如下： Record Lock：单个行记录上的锁 Gap Lock：间隙锁，锁定一个范围，但不包含记录本身 Next-Key Lock：Record Lock + Gap Lock，锁定一个范围，并且锁定记录本身

不同事务隔离级别下的加锁行为不同 一般来说，InnoDB 的加锁规则至少取决于如下因素：

当前系统的事务隔离级别； 查询/更新条件是否为主键； 如果查询条件不包含主键，是否包含二级索引，二级索引对应的数据是否唯一； SQL 语句的执行计划，是执行全表扫描还是索引扫描。

InnoDB 提供了 SQL:1992 标准中描述的所有四种事务隔离级别：READ UNCOMMITTED、READ COMMITTED、REPEATABLE READ和SERIALIZABLE。InnoDB 的默认隔离级别是REPEATABLE READ。 InnoDB 支持使用不同的锁定策略来实现这里描述的每个事务隔离级别

RU隔离级别（Read Uncommited ）：不加锁。串行化隔离级别（Serializable）：所有的 select 语句都会被隐式的转化为 select ... in share mode，会和 update、delete 操作互斥。RR隔离级别（Repeatable Read）：普通的 select 使用快照读（snapshotread），底层使用 MVCC 来实现；加锁的 select（select ... in share mode / select ... for update）以及更新操作 update、delete 等语句使用当前读（current read），底层使用记录锁、或者间隙锁、临键锁来实现。RC隔离级别（Read Commited）：普通的 select 都是快照读，使用 MVCC 实现，加锁的 select 都使用记录锁，因为没有间隙锁(Gap Locks)。



double write的根本原因是文件系统不能保证写数据页是一个原子操作
 为什么不可以使用固态ssd来替代内存，了解存储器层次结构 内存ram和ssd之间还是差了好几个数量级的，其实还是成本问题，内存的ram更贵
mvcc的思路就是读写互相不block 这样就减少了一堆锁冲突，其实使用2pl也可以实现读写事务 只是性能糟糕
布隆过滤器实现的功能和hashset一样 在O1的时间复杂度判断元素是否在集合中， 通过多个hash减少了冲突的概率 也节省了空间 缺点是假阳性所以不支持删除
分库分表的目的是解决两个问题 1.单台机器的硬件资源cpu io disk memory是有限  2机器是会坏的  解决方案就是分片和容错   分片的策略是由需求决定的

锁相关 锁分类 为什么需要锁 lock是逻辑锁锁的是事务 表 索引，是数据库层面抽象的锁(记录锁 表锁 全局锁) latch是物理锁 锁的是内存中的tuple block是os层面的锁(mutex rwlock spinlock)